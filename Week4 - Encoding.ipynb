{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# load example long jump dataset\n",
    "df = pd.read_csv(\"./data/long_jump.csv\")\n",
    "df.set_index('Person', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Jersey Size  Shoe Size\n",
      "Person                        \n",
      "Thomas        small          7\n",
      "Jane         medium         10\n",
      "Vaughn        large         12\n",
      "Vera         medium          9\n",
      "Vincent       large         12\n",
      "Lei-Ann       small          7\n"
     ]
    }
   ],
   "source": [
    "# filter in categorical columns for demonstration\n",
    "cats = ['Jersey Size', 'Shoe Size']\n",
    "print(df[cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module and instatiate enc object\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identified categories:\n",
      "[array(['large', 'medium', 'small'], dtype=object), array([ 7,  9, 10, 12])]\n",
      "encoded_data:\n",
      "[[2. 0.]\n",
      " [1. 2.]\n",
      " [0. 3.]\n",
      " [1. 1.]\n",
      " [0. 3.]\n",
      " [2. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#fit and transform in one call and print categories\n",
    "out_enc = enc.fit_transform(df[cats])\n",
    "print('identified categories:')\n",
    "print(enc.categories_)\n",
    "print('encoded_data:')\n",
    "print(out_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Age  Height  Weight  Training Hours/week Jersey Color  Jersey Size  \\\n",
      "Person                                                                        \n",
      "Thomas    12    57.5    73.4                  6.5         blue          2.0   \n",
      "Jane      13    65.5    85.3                  8.9        green          1.0   \n",
      "Vaughn    17    71.9   125.9                  1.1        green          0.0   \n",
      "Vera      14    65.3   100.5                  7.9          red          1.0   \n",
      "Vincent   18    70.1   110.7                 10.5         blue          0.0   \n",
      "\n",
      "         Shoe Size  Long Jump  \n",
      "Person                         \n",
      "Thomas         0.0       19.2  \n",
      "Jane           2.0       25.1  \n",
      "Vaughn         3.0       14.3  \n",
      "Vera           1.0       18.3  \n",
      "Vincent        3.0       21.1  \n"
     ]
    }
   ],
   "source": [
    "# overwrite categorical features in original dataframe\n",
    "df[cats] = out_enc\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jersey Size_0.0', 'Jersey Size_1.0', 'Jersey Size_2.0', 'Shoe Size_0.0', 'Shoe Size_1.0', 'Shoe Size_2.0', 'Shoe Size_3.0']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(sparse = False)\n",
    "\n",
    "out_enc = enc.fit_transform(df[cats])\n",
    "new_cols = enc.get_feature_names(cats).tolist()\n",
    "print(new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Height', 'Weight', 'Training Hours/week', 'Jersey Color',\n",
      "       'Long Jump', 'Jersey Size_0.0', 'Jersey Size_1.0', 'Jersey Size_2.0',\n",
      "       'Shoe Size_0.0', 'Shoe Size_1.0', 'Shoe Size_2.0', 'Shoe Size_3.0'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# create temporary dataframe \"df_enc\" for concatenation with original data\n",
    "df_enc = pd.DataFrame(data= out_enc, columns = new_cols)\n",
    "df_enc.index = df.index\n",
    "\n",
    "#drop original columns and concat new encoded columns\n",
    "df. drop(cats, axis=1, inplace = True)\n",
    "df = pd.concat([df,df_enc], axis =1 )\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lable Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.preprocessing' has no attribute 'LableEncoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-265bc31ffd22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLableEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mout_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn.preprocessing' has no attribute 'LableEncoder'"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "enc = preprocessing.LableEncoder()\n",
    "\n",
    "out_enc = enc.fit_transform([1,2,5,2,4,2,5])\n",
    "print(out_enc)\n",
    "\n",
    "out_enc = enc.fit_transform(['blue','red','blue','green','red','red'])\n",
    "print(out_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
